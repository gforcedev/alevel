\section{Matrices}
\subsection{Matrix basics}
A matrix is an array of elements.

\subsubsection{Dimensions}
We define matrices as being $n$x$m$, where $n$ is the number of rows and $m$ is the number of columns. A vector (can be a row vector or a column vector), has one of its dimensions equal to 1. If $m=n$ then the matrix is a square matrix.

\subsubsection{Special matrices}
A zero matrix has all elements equal to zero:
\begin{ea}
	\begin{pmatrix}0 & 0 & 0 \\ 0 & 0 & 0\end{pmatrix}
\end{ea}

An identity matrix of a certian dimension, represented by $\mathbf{I_k}$, has 1s on the leading diagonal:

\begin{ea}[rCl]
	\mathbf{I_2} & = & \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}
	\nonumber\\
	\mathbf{I_3} & = & \begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}
\end{ea}

\subsubsection{Some conventions}
In print, letters representing matrices are usually bolded. When handwritten, they're often underlined. Most matrix letters are also capitalised.

\subsection{Operations of matrices}
\subsubsection{Addition and subtraction}
Adding and subtracting can be done on matrices of the same dimensions. If two matrices are the same dimensions they're said to be additively conformable. The corresponding elements are added or subtracted.
\begin{ea}[rCl]
	\begin{pmatrix}1 & 2 \\ 3 & 4\end{pmatrix} +
	\begin{pmatrix}5 & 6 \\ 7 & 8\end{pmatrix} & = &
	\begin{pmatrix}6 & 8 \\ 10 & 12\end{pmatrix}
\end{ea}

\subsubsection{Multiplying by scalars}
Matrices can be multiplied by scalars by multiplying every element by the scalar.
\begin{ea}[rCl]
	\begin{pmatrix}1 & 2 \\ 3 & 4\end{pmatrix}
	\times 2 & = &
	\begin{pmatrix}2 & 4 \\ 6 & 8\end{pmatrix}
\end{ea}

\subsection{Matrix multiplication}
\subsubsection{Dimensions and requirements}
Matrices can be multiplied if the number of columns of the first is equal to the number of rows of the second. The product matrix will have dimensions of the number of rows of the first matrix, and the number of the columns of the second. It's easiest to think of it like:
\begin{ea}[lCr]
	(n_1\times m_1) & \times & (n_2\times m_2)
\end{ea}
The inner two must be equal for it to be possible, and the outer two will be the dimensions of the result. If the requirements are met, the two matrices are said to be multiplicatively conformable.

\subsubsection{Actually multiplying matrices}
To multiply matrices, multiply the elements in each row by the elements from the corresponding column, moving down one at a time:
\begin{ea}[rCl]
	\begin{pmatrix}a & b \\ c & d\end{pmatrix} \times
	\begin{pmatrix}e & f \\ g & h\end{pmatrix} & = &
	\begin{pmatrix}ae + bg & af + bh \\ ce + dg & cf + dh\end{pmatrix}
\end{ea}

Note that this means matrix multiplication is non-commutative. It may only be possible one way round, and if it's possible either way then $\mathbf{AB}$ does not necessarily equal $\mathbf{BA}$.

\subsection{Determinants}
The determinant of a matrix is a scalar, and it only exists if the matrix is square. It can be notated in a few ways:
\begin{ea}
	|\mathbf{M}| = \det \mathbf{M} = \left|\begin{pmatrix}a & b \\ c & d\end{pmatrix}\right|
\end{ea}

\subsubsection{Singular matrices}
If $|\mathbf{M}|=0$, then $\mathbf{M}$ is a singular matrix. Otherwise, it's non-singular.

\subsubsection{Determinants of 2x2 matrices}
The determinant of a 2x2 matrix is the product of the leading diagonal, minus the product of the other diagonal.
\begin{ea}[rCl]
	\left|\begin{pmatrix}a & b \\ c & d\end{pmatrix}\right| & = &
	ad - bc
\end{ea}

\subsubsection{Determinants of 3x3 matrices}
The determinant of a 3x3 matrix is found by going along the top row, and alternately adding and subtracting the element multiplied by its minor.

The minor of an element is the determinant of the matrix that would be found if that element's row and column were crossed out.
\begin{ea}[rCl]
	\left|\begin{pmatrix}
		a & b & c \\ d & e & f \\ g & h & i
	\end{pmatrix}\right| & = &
	a\left|\begin{pmatrix}e & f \\ h & i \end{pmatrix}\right| -
	b\left|\begin{pmatrix}a & f \\ g & i \end{pmatrix}\right| +
	c\left|\begin{pmatrix}d & e \\ g & h \end{pmatrix}\right|
\end{ea}

\subsection{Inverting matrices}
The inverse of matrix $\mathbf{M}$, denoted as $\mathbf{M^{-1}}$, is defined such that $\mathbf{MM^{-1}}=\mathbf{M^{-1}M}=\mathbf{I}$. Any non-singular matrix has an inverse.

\subsubsection{Inverting products of matrices}
If both $\mathbf{A}$ and $\mathbf{B}$ are non-singular, then ($\mathbf{AB})^{-1}=\mathbf{B}^{-1}\mathbf{A}^{-1}$. The proof for this  starts by letting $(\mathbf{AB})^{-1} = \mathbf{C}$ and then uses the useful trick of pre-multiplying by an inverse matrix in order to cancel it on one side:

\begin{ea}[rCl]
	(\mathbf{AB})\mathbf{C} & = & \mathbf{I}
	\nonumber\\
	\mathbf{ABC} & = & \mathbf{I}
	\nonumber\\
	\mathbf{A}^{-1}\mathbf{AB}\mathbf{C} & = & \mathbf{A}^{-1}\mathbf{I}
	\nonumber\\
	\mathbf{BC} & = & \mathbf{A}^{-1}\mathbf{I}
	\nonumber\\
	\mathbf{B}^{-1}\mathbf{BC} & = & \mathbf{B}^{-1}\mathbf{A}^{-1}\mathbf{I}
	\nonumber\\
	\mathbf{C} & = & \mathbf{B}^{-1}\mathbf{A}^{-1}\mathbf{I}
	\nonumber\\
	\mathbf{C} & = & \mathbf{B}^{-1}\mathbf{A}^{-1}
	\nonumber\\
	(\mathbf{AB})^{-1} & = & \mathbf{B}^{-1}\mathbf{A}^{-1}
\end{ea}

\subsubsection{Inverting 2x2 matrices}
To invert a 2x2 matrix, swap the elements on the leading diagonal, and multiply the elements on the other diagonal by $-1$. Then take the entire matrix and multiply by 1 over the determinant:

\begin{ea}[rCl]
	\begin{pmatrix}a & b \\ c & d\end{pmatrix}^{-1} & = &
	\frac{1}{\det \mathbf{M}}\begin{pmatrix}d & -b \\ -c & a\end{pmatrix}
\end{ea}

\subsubsection{Inverting 3x3 matrices}
To invert a 3x3 matrix $\mathbf{A}$, first find the determinant. Then find the matrix of minors of $\mathbf{A}$, usually denoted as $\mathbf{M}$, which is found by replacing each element with its minor. The next step is to find what's called the matrix of cofactors, $\mathbf{C}$, which is done by multiplying the four elements in the middle of each outer row and column of $\mathbf{M}$ by -1. Then, find the transpose of $\mathbf{C}$, denoted as $\mathbf{C^T}$. The transpose of a matrix is found by swapping the rows and columns. Multiply this by 1 over the original determinant to get the inverse matrix of $\mathbf{M}$.

An example with working:

\begin{ea}[rCl]
	\mathbf{A} & = &
	\begin{pmatrix}1 & 3 & 1 \\ 0 & 4 & 1 \\ 2 & -1 & 0\end{pmatrix}
	\nonumber\\
	\det \mathbf{A} & = & 1 \times 1 - 3 \times -2 + 1 \times -8
	\nonumber\\
	& = & -1
	\nonumber\\
	\mathbf{M} & = &
	\begin{pmatrix}1 & -2 & -8 \\ 1 & -2 & -7 \\ -1 & 1 & 4\end{pmatrix}
	\nonumber\\
	\mathbf{C} & = &
	\begin{pmatrix}1 & 2 & -8 \\ -1 & -2 & 7 \\ -1 & -1 & 4\end{pmatrix}
	\nonumber\\
	\mathbf{C^T} & = &
	\begin{pmatrix}1 & -1 & -1 \\ 2 & -2 & -1 \\ -8 & 7 & 4\end{pmatrix}
	\nonumber\\
	\mathbf{A}^{-1} & = & \frac{1}{-1}
	\begin{pmatrix}1 & -1 & -1 \\ 2 & -2 & -1 \\ -8 & 7 & 4\end{pmatrix}
	\nonumber\\
	& = &
	\begin{pmatrix}-1 & 1 & 1 \\ -2 & 2 & 1 \\ 8 & -7 & -4\end{pmatrix}
\end{ea}

\subsection{Solving systems of equations with matrices}
Systems of three simultaneous equations can be solved using matrices to represent them. This is because:

\begin{ea}[rCl]
	\begin{pmatrix}a & b & c \\ d & e & f \\ g & h & i\end{pmatrix}
	\begin{pmatrix}x \\ y \\ z \end{pmatrix} & = &
	\begin{pmatrix}ax + by + cz \\ dx + ey + fz \\ gx + hy + iz\end{pmatrix}
\end{ea}

is similar to and can represent the system

\begin{ea}[rCl]
	ax + by + cz = p
	\nonumber\\
	dx + ey + fz = q
	\nonumber\\
	gx + hy + iz = r
\end{ea}

If we denote the first matrix as $\mathbf{A}$, the second as ${\mathbf{v}}$, and the third as $\mathbf{b}$ then given a system of three simultaneous equations we can construct $\mathbf{A}$ and $\mathbf{b}$. Then, to find $\mathbf{v}$ and thus the values of $x$, $y$, and $z$, we can use:

\begin{ea}[rCl]
	\mathbf{Av} & = & \mathbf{b}
	\nonumber\\
	\mathbf{A}^{-1}\mathbf{Av} & = & \mathbf{A}^{-1}\mathbf{b}
	\nonumber\\
	\mathbf{v} = \mathbf{A}^{-1}\mathbf{b}
\end{ea}

This can only exist if $\mathbf{A}$, the coefficient matrix, is non-singular. If this isn't the case, then the system doesn't have a solution.

\subsubsection{What if the coefficient matrix is singular?}
If the coefficient matrix is singular, then either there are infinitely many solutions, or no solutions. A system is defined as consistent if it has $\leq 1$ solution, otherwise it's defined as inconsistent.

Just as a line in 2d space can be represented by equations in the form $ax + by = c$, then a plane in 3d space can be represented by equations such as the ones in these systems, in the form $ax + by + cz = d$. For there to be one unique solution, these planes have to all meet at a single point. This is what happens when the coefficient matrix is non-singular.

For there to be infinitely solutions, there has to be infinitely points the planes meet. This can happen if they represent a sheaf (there's one line where they all meet), or if two or more of the same plane are represented.

For there to be no solutions, there has to be no points where all three planes intersect. This can happen if two of the planes represented are parallel, which can be checked by looking to see if two of the equations are linear multiples of each other.
